{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ypZa6jg0rZy"
      },
      "source": [
        "## MNIST Clan-ssifier Model 2 - CNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install ezkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fm2DMmXW0rZ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# install ezkl\n",
        "\n",
        "import ezkl\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "\n",
        "\n",
        "# uncomment for more descriptive logging\n",
        "FORMAT = '%(levelname)s %(name)s %(asctime)-15s %(filename)s:%(lineno)d %(message)s'\n",
        "logging.basicConfig(format=FORMAT)\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jbRkAJLz0rZ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # Convolutional encoder\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)  # 1 input channel, 6 output channels, 5x5 kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
        "\n",
        "        # Fully connected layers / Dense block\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120) \n",
        "        self.fc2 = nn.Linear(120, 84)         # 120 inputs, 84 outputs\n",
        "        self.fc3 = nn.Linear(84, 10)          # 84 inputs, 10 outputs (number of classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional block\n",
        "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
        "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
        "\n",
        "        # Flattening\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)  # No activation function here, will use CrossEntropyLoss later\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torchvision.datasets import mnist\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam  # Import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  return torch.round(image), label\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "batch_size = 256\n",
        "train_dataset = mnist.MNIST(root='./train', train=True, transform=ToTensor(), download=True)\n",
        "test_dataset = mnist.MNIST(root='./test', train=False, transform=ToTensor(), download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "model = LeNet().to(device)\n",
        "adam = Adam(model.parameters())  # Using Adam with a learning rate of 1e-3\n",
        "loss_fn = CrossEntropyLoss()\n",
        "all_epoch = 25\n",
        "prev_acc = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchsummary import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 24, 24]             156\n",
            "            Conv2d-2             [-1, 16, 8, 8]           2,416\n",
            "            Linear-3                  [-1, 120]          30,840\n",
            "            Linear-4                   [-1, 84]          10,164\n",
            "            Linear-5                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 0.17\n",
            "Estimated Total Size (MB): 0.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model,(1,28,28))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yYNrvus0rZ2",
        "outputId": "d3ae2380-fa03-4368-9bea-46c38a65ddca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy: 0.723\n",
            "test accuracy: 0.852\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     predict_y \u001b[38;5;241m=\u001b[39m model(train_x\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(predict_y, train_label\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     adam\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Use adam optimizer\u001b[39;00m\n\u001b[1;32m     36\u001b[0m all_correct_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/zkml/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/zkml/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/zkml/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "for current_epoch in range(all_epoch):\n",
        "    model.train()\n",
        "    for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "        train_x = train_x.to(device)\n",
        "        # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
        "        train_x = train_x.round()\n",
        "        train_label = train_label.to(device)\n",
        "        adam.zero_grad()  # Use adam optimizer\n",
        "        predict_y = model(train_x.float())\n",
        "        loss = loss_fn(predict_y, train_label.long())\n",
        "        loss.backward()\n",
        "        adam.step()  # Use adam optimizer\n",
        "    all_correct_num = 0\n",
        "    all_sample_num = 0\n",
        "    model.eval()\n",
        "\n",
        "    for idx, (test_x, test_label) in enumerate(test_loader):\n",
        "        test_x = test_x.to(device)\n",
        "         # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
        "        test_x = test_x.round()\n",
        "        test_label = test_label.to(device)\n",
        "        predict_y = model(test_x.float()).detach()\n",
        "        predict_y = torch.argmax(predict_y, dim=-1)\n",
        "        current_correct_num = predict_y == test_label\n",
        "        all_correct_num += np.sum(current_correct_num.to('cpu').numpy(), axis=-1)\n",
        "        all_sample_num += current_correct_num.shape[0]\n",
        "    acc = all_correct_num / all_sample_num\n",
        "    print('test accuracy: {:.3f}'.format(acc), flush=True)\n",
        "    if not os.path.isdir(\"models\"):\n",
        "        os.mkdir(\"models\")\n",
        "    torch.save(model, 'models/mnist_{:.3f}.pkl'.format(acc))\n",
        "    prev_acc = acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the saved model checkpoint with highest accuracy\n",
        "model = torch.load(\"models/mnist_0.979.pkl\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "# generate a confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# visualize confusion matrix with matplotlib and seaborn\n",
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "ax = sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", ax=ax, cmap=\"viridis\")\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "ax.set_title(\"Confusion Matrix\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
            "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
            "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
            "        1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
            "        7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n",
            "        2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 5, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2,\n",
            "        8, 5, 8, 6, 7, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9,\n",
            "        7, 0, 9, 2, 9, 5, 1, 5, 9, 1, 2, 3, 2, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5,\n",
            "        0, 7, 4, 9, 7, 8, 3, 2, 1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 0, 1, 7, 2, 7, 3,\n",
            "        0, 4, 6, 5, 2, 6, 4, 7, 1, 8, 9, 9, 3, 0, 7, 1, 0, 2, 0, 3, 5, 4, 6, 5,\n",
            "        8, 6, 3, 7, 5, 8, 0, 9, 1, 0, 3, 1, 2, 2, 3, 3])\n",
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
            "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
            "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
            "        1, 6, 3, 0, 2, 1, 1, 7, 0, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
            "        7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n",
            "        2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 3, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2,\n",
            "        8, 5, 8, 6, 9, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9,\n",
            "        7, 0, 9, 2, 7, 5, 1, 5, 9, 1, 2, 3, 2, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5,\n",
            "        0, 7, 4, 9, 7, 8, 3, 2, 1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 0, 1, 1, 2, 7, 3,\n",
            "        0, 4, 6, 5, 2, 6, 4, 7, 2, 8, 9, 9, 3, 0, 7, 1, 0, 2, 0, 3, 5, 4, 6, 5,\n",
            "        8, 6, 3, 7, 5, 8, 0, 9, 1, 0, 3, 1, 2, 2, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "# test the trained model\n",
        "\n",
        "for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "    print(train_label) #, train_x)\n",
        "    train_x = train_x.to(device)\n",
        "    # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n",
        "    train_x = train_x.round()\n",
        "    train_label = train_label.to(device)\n",
        "    prediction = model(train_x.float())\n",
        "    \n",
        "    # print(\"prediction: \",prediction)\n",
        "    predict_decoded = torch.argmax(prediction, dim=-1)\n",
        "    print(predict_decoded)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -5.8988,  -2.4977,  -7.1422,  ...,  -2.6770,  -2.5237,  -1.8794],\n",
            "        [  9.6284, -11.8113,  -1.4953,  ...,  -4.2926,  -2.7603,  -0.1944],\n",
            "        [ -6.5762,  -3.2895,  -2.1786,  ...,  -1.0354,  -6.0388,  -0.8894],\n",
            "        ...,\n",
            "        [ -4.3042,  -2.8652,   7.9514,  ...,  -1.4231,  -2.2178,  -5.2027],\n",
            "        [ -4.5936,  -3.0156,  -2.0817,  ...,  -2.7231,  -1.0167,  -1.1353],\n",
            "        [ -5.3895,  -2.0177,  -1.9035,  ...,  -0.8790,   0.5988,  -1.9552]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# checking output logits of the model\n",
        "prediction = model(train_x.float())\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implement Zero-Knowledge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tmGo25eb0rZ3"
      },
      "outputs": [],
      "source": [
        "# define files and respective paths\n",
        "\n",
        "model_path = os.path.join('network_lenet.onnx')\n",
        "compiled_model_path = os.path.join('network.compiled')\n",
        "pk_path = os.path.join('key.pk')\n",
        "vk_path = os.path.join('key.vk')\n",
        "settings_path = os.path.join('settings.json')\n",
        "witness_path = os.path.join('witness.json')\n",
        "data_path = os.path.join('input.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000, 0.0000, 0.0000]]]]) 5\n"
          ]
        }
      ],
      "source": [
        "# # Fetch a single data point from the train_dataset\n",
        "# # Ensure train_dataset is already loaded and accessible\n",
        "train_data_point, actual_label = next(iter(train_dataset))\n",
        "train_data_point = train_data_point.unsqueeze(0)  # Add a batch dimension\n",
        "print(train_data_point,actual_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "RfFjaXrM0rZ3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model exported to network_lenet.onnx and input data saved to input.json\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "\n",
        "# Verify the device (CPU or CUDA) and transfer the data point to the same device as the model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_data_point = train_data_point.to(device)\n",
        "\n",
        "# # Export the model to ONNX format\n",
        "torch.onnx.export(model, train_data_point, model_path, export_params=True, opset_version=10, do_constant_folding=True, input_names=['input_0'], output_names=['output'])\n",
        "\n",
        "# Convert the tensor to numpy array and reshape it for JSON serialization\n",
        "x = train_data_point.cpu().detach().numpy().reshape([-1]).tolist()\n",
        "data = {'input_data': [x]}\n",
        "with open('input.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "print(f\"Model exported to {model_path} and input data saved to input.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if training is false\n",
        "model.training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test onnx model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def reverse_array_shape(x):\n",
        "    original_shape = (1, 28, 28)  # Replace with the actual shape of the original tensor\n",
        "    \n",
        "    # Convert the list back to a numpy array\n",
        "    numpy_array = np.array(x)\n",
        "\n",
        "    # Reshape the numpy array to the original shape\n",
        "    reshaped_array = numpy_array.reshape(original_shape)\n",
        "\n",
        "    # Convert the numpy array back to a tensor\n",
        "    train_data_point_reconstructed = torch.tensor(reshaped_array)\n",
        "    return train_data_point_reconstructed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dS-yXte30rZ3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.execute 2024-06-16 10:42:06,171 execute.rs:968 num calibration batches: 1\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,154 table.rs:165 Using 2 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,156 table.rs:165 Using 2 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,158 table.rs:165 Using 2 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,160 table.rs:165 Using 2 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,163 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,168 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,172 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,176 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,178 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,182 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,188 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:16,208 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:23,454 table.rs:165 Using 2 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:23,456 table.rs:165 Using 2 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:23,459 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:23,461 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:23,468 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.circuit.table 2024-06-16 10:42:23,471 table.rs:165 Using 3 columns for non-linearity table.\n",
            "WARNING ezkl.execute 2024-06-16 10:42:28,116 execute.rs:1287 \n",
            "\n",
            " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
            "\n",
            "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
            "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
            "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
            "| 0.03359096 | 0.05500412   | 1.5213902 | -1.5799055 | 0.808053       | 0.05500412       | 1.5799055     | 0.053876877   | 0.9895749          | -0.005673811       | 0.26911557             |\n",
            "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import ezkl\n",
        "\n",
        "# define visibility or the model inputs and outputs\n",
        "run_args = ezkl.PyRunArgs()\n",
        "run_args.input_visibility = \"private\"\n",
        "run_args.param_visibility = \"fixed\"\n",
        "run_args.output_visibility = \"public\"\n",
        "run_args.num_inner_cols = 2\n",
        "run_args.variables = [(\"batch_size\", 1)]\n",
        "\n",
        "# Capture set of data points \n",
        "# Analyze caloibrated model with different data points eg- 1,3,30\n",
        "num_data_points = 1\n",
        "\n",
        "# Fetch 30 data points from the train_dataset\n",
        "data_points = []\n",
        "for i, (data_point, _) in enumerate(train_dataset):\n",
        "    if i >= num_data_points:\n",
        "        break\n",
        "    data_points.append(data_point)\n",
        "\n",
        "# Stack the data points to create a batch\n",
        "train_data_batch = torch.stack(data_points)\n",
        "\n",
        "# Add a batch dimension if not already present\n",
        "if train_data_batch.dim() == 3:\n",
        "    train_data_batch = train_data_batch.unsqueeze(0)\n",
        "\n",
        "x = train_data_batch.cpu().detach().numpy().reshape([-1]).tolist()\n",
        "\n",
        "data = dict(input_data = [x])\n",
        "\n",
        "cal_path = os.path.join('cal_data.json')\n",
        "\n",
        "# Serialize data into file:\n",
        "json.dump( data, open(cal_path, 'w' ))\n",
        "\n",
        "!RUST_LOG=trace\n",
        "# TODO: Dictionary outputs\n",
        "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
        "assert res == True\n",
        "\n",
        "res = await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\", scales=[2,7])\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "pGb1nj720rZ3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Circuit compiled successfully...!\n"
          ]
        }
      ],
      "source": [
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True\n",
        "if res:\n",
        "    print( \"Circuit compiled successfully...!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "umpLxVAI0rZ3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SRS was successfully fetched\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.execute 2024-06-16 10:43:34,728 execute.rs:672 SRS already exists at that path\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.execute 2024-06-16 10:43:35,558 execute.rs:570 read 16777476 bytes from file (vector of len = 16777476)\n",
            "INFO ezkl.execute 2024-06-16 10:43:35,720 execute.rs:577 file hash: 41509f380362a8d14401c5ae92073154922fe23e45459ce6f696f58607655db7\n"
          ]
        }
      ],
      "source": [
        "# (Structured Reference String)srs path\n",
        "srs_path=\"kzg.srs\"\n",
        "\n",
        "# get the SRS string\n",
        "try:\n",
        "  res = ezkl.get_srs(srs_path=srs_path,\n",
        "                     settings_path=settings_path)\n",
        "  if res:\n",
        "    print(\"SRS was successfully fetched\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "syLy2Kt90rZ3"
      },
      "outputs": [],
      "source": [
        "# now generate the witness file\n",
        "witness_path = \"witness.json\"\n",
        "\n",
        "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test ZKML Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-6.41455078125, -1.057373046875, -6.493408203125, 4.5693359375, -10.150146484375, 7.39404296875, -7.16015625, -1.08544921875, -3.865966796875, -2.697021484375]\n"
          ]
        }
      ],
      "source": [
        "# convert the quantized ezkl output to float value\n",
        "with open(witness_path) as f:\n",
        "    wit_data = json.load(f)\n",
        "outputs = wit_data[\"outputs\"]\n",
        "with open(settings_path) as f:\n",
        "    settings = json.load(f)\n",
        "ezkl_outputs = [ezkl.felt_to_float(outputs[0][i], settings[\"model_output_scales\"][0]) for i in range(10) ]\n",
        "print( ezkl_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5)\n"
          ]
        }
      ],
      "source": [
        "# Convert the list to a tensor\n",
        "ezkl_witnessed_prediction = torch.tensor(ezkl_outputs)\n",
        "\n",
        "# Reshape the tensor if needed (not necessary in this case as it's already the correct shape)\n",
        "# ezkl_outputs = ezkl_outputs.view(1, -1)  # Uncomment this line if ezkl_outputs should have shape (1, 10)\n",
        "\n",
        "# Apply the model's prediction decoding (e.g., argmax to get the predicted class)\n",
        "predict_decoded = torch.argmax(ezkl_witnessed_prediction, dim=-1)\n",
        "\n",
        "# Print the predicted class\n",
        "print(predict_decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "65u_ObBQ0rZ4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.execute 2024-06-16 10:46:50,466 execute.rs:1334 Mock proof\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.graph.model 2024-06-16 10:46:50,963 model.rs:1097 model layout...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mock proof run was successful\n"
          ]
        }
      ],
      "source": [
        "# mock proof for sanity check\n",
        "# if this is successfull we are good to setup the model\n",
        "try:\n",
        "  res = ezkl.mock(witness=witness_path,\n",
        "                  model=compiled_model_path)\n",
        "  if res:\n",
        "    print(\"Mock proof run was successful\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "c8GIoMD40rZ4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.pfsys.srs 2024-06-16 10:47:43,146 srs.rs:34 loading srs from \"/home/gk/.ezkl/srs/kzg17.srs\"\n",
            "INFO ezkl.execute 2024-06-16 10:47:43,452 execute.rs:2482 downsizing params to 17 logrows\n",
            "INFO ezkl.graph.model 2024-06-16 10:47:43,586 model.rs:1097 model layout...\n",
            "INFO ezkl.pfsys 2024-06-16 10:48:06,332 mod.rs:512 VK took 22.878\n",
            "INFO ezkl.graph.model 2024-06-16 10:48:06,345 model.rs:1097 model layout...\n",
            "INFO ezkl.pfsys 2024-06-16 10:48:28,591 mod.rs:518 PK took 22.258\n",
            "INFO ezkl.pfsys 2024-06-16 10:48:28,594 mod.rs:804 saving verification key \n",
            "INFO ezkl.pfsys 2024-06-16 10:48:28,603 mod.rs:809 done saving verification key \n",
            "INFO ezkl.pfsys 2024-06-16 10:48:28,604 mod.rs:787 saving proving key \n",
            "INFO ezkl.pfsys 2024-06-16 10:48:41,205 mod.rs:792 done saving proving key \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# HERE WE SETUP THE CIRCUIT PARAMS\n",
        "# WE GOT KEYS\n",
        "# WE GOT CIRCUIT PARAMETERS\n",
        "# EVERYTHING NEED FOR IMPLEMENTING ZK WITH ML\n",
        "\n",
        "res = ezkl.setup(\n",
        "        compiled_model_path,\n",
        "        vk_path,\n",
        "        pk_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "vkIutAhR0rZ4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.pfsys 2024-06-16 10:49:30,621 mod.rs:766 loading proving key from \"key.pk\"\n",
            "INFO ezkl.pfsys 2024-06-16 10:49:33,752 mod.rs:775 done loading proving key \n",
            "INFO ezkl.pfsys.srs 2024-06-16 10:49:33,754 srs.rs:34 loading srs from \"kzg.srs\"\n",
            "INFO ezkl.execute 2024-06-16 10:49:33,795 execute.rs:2482 downsizing params to 17 logrows\n",
            "INFO ezkl.pfsys 2024-06-16 10:49:33,798 mod.rs:573 proof started...\n",
            "INFO ezkl.graph.model 2024-06-16 10:49:33,890 model.rs:1097 model layout...\n",
            "INFO ezkl.pfsys 2024-06-16 10:50:31,016 mod.rs:612 proof took 57.216\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proof was successfully generated\n",
            "{'instances': [['5f99ffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '16efffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '1c98ffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '1c49000000000000000000000000000000000000000000000000000000000000', '9a5dffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '4e76000000000000000000000000000000000000000000000000000000000000', '718dffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', 'a3eeffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '26c2ffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', 'dad4ffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430']], 'proof': '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', 'transcript_type': 'EVM'}\n"
          ]
        }
      ],
      "source": [
        "# GENERATE A PROOF\n",
        "\n",
        "# proof path\n",
        "proof_path = os.path.join('test.pf')\n",
        "\n",
        "# generate proof\n",
        "try:\n",
        "    res = ezkl.prove(\n",
        "        witness= witness_path,\n",
        "        model =  compiled_model_path,\n",
        "            pk_path=pk_path,\n",
        "            proof_path= proof_path,\n",
        "            srs_path=\"kzg.srs\",\n",
        "            proof_type=\"single\")\n",
        "    if res:\n",
        "        print(\"Proof was successfully generated\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n",
        "\n",
        "# check oif proof file is generated\n",
        "print(res)\n",
        "assert os.path.isfile(proof_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KmpQBZUT0rZ4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.pfsys.srs 2024-06-16 10:58:11,548 srs.rs:23 loading srs from \"kzg.srs\"\n",
            "INFO ezkl.execute 2024-06-16 10:58:11,629 execute.rs:2467 downsizing params to 17 logrows\n",
            "INFO ezkl.pfsys 2024-06-16 10:58:11,632 mod.rs:743 loading verification key from \"key.vk\"\n",
            "INFO ezkl.pfsys 2024-06-16 10:58:11,649 mod.rs:752 done loading verification key \n",
            "INFO ezkl.execute 2024-06-16 10:58:11,685 execute.rs:2373 verify took 0.28\n",
            "INFO ezkl.execute 2024-06-16 10:58:11,686 execute.rs:2378 verified: true\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proof was successfully verified\n"
          ]
        }
      ],
      "source": [
        "# verify proof\n",
        "try:\n",
        "  res = ezkl.verify(proof_path=proof_path,\n",
        "                    settings_path=settings_path,\n",
        "                    vk_path=vk_path,\n",
        "                    srs_path=\"kzg.srs\")\n",
        "  if res:\n",
        "    print(\"Proof was successfully verified\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ2CYQdm0rZ4"
      },
      "source": [
        "We can now create an EVM / `.sol` verifier that can be deployed on chain to verify submitted proofs using a view function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "jASymUWQ0rZ4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.pfsys.srs 2024-06-16 10:59:36,222 srs.rs:23 loading srs from \"kzg.srs\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.execute 2024-06-16 10:59:36,266 execute.rs:2467 downsizing params to 17 logrows\n",
            "INFO ezkl.pfsys 2024-06-16 10:59:36,267 mod.rs:743 loading verification key from \"key.vk\"\n",
            "INFO ezkl.pfsys 2024-06-16 10:59:36,286 mod.rs:752 done loading verification key \n"
          ]
        }
      ],
      "source": [
        "srs_path=\"kzg.srs\"\n",
        "\n",
        "abi_path = 'solidity_verifier.abi'\n",
        "sol_code_path = 'solidity_verifier.sol'\n",
        "\n",
        "res = await ezkl.create_evm_verifier(\n",
        "        vk_path,\n",
        "        settings_path,\n",
        "        sol_code_path,\n",
        "        abi_path,\n",
        "        srs_path\n",
        "    )\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-icN2yw60rZ5"
      },
      "source": [
        "## Verify on the evm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sTLsLwaC0rZ5"
      },
      "outputs": [],
      "source": [
        "# Make sure anvil is running locally first\n",
        "# run with $ anvil -p 3030\n",
        "\n",
        "# we use the default anvil node here\n",
        "import json\n",
        "import ezkl \n",
        "import os\n",
        "\n",
        "address_path = os.path.join(\"address.json\")\n",
        "sol_code_path = 'solidity_verifier.sol'\n",
        "\n",
        "\n",
        "res = await ezkl.deploy_evm(\n",
        "    address_path,\n",
        "    sol_code_path,\n",
        "    'http://127.0.0.1:3030'\n",
        ")\n",
        "\n",
        "assert res == True\n",
        "\n",
        "# Save the block hash where contract is deployed\n",
        "with open(address_path, 'r') as file:\n",
        "    addr = file.read().rstrip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "PrSyQK4B0rZ5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.eth 2024-06-16 11:01:06,319 eth.rs:283 using chain 31337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO ezkl.eth 2024-06-16 11:01:06,939 eth.rs:595 estimated verify gas cost: 715309\n",
            "INFO ezkl.execute 2024-06-16 11:01:06,941 execute.rs:1602 Solidity verification result: true\n"
          ]
        }
      ],
      "source": [
        "# make sure anvil is running locally\n",
        "# $ anvil -p 3030\n",
        "proof_path = os.path.join('test.pf')\n",
        "\n",
        "res = await ezkl.verify_evm(\n",
        "    addr,\n",
        "    proof_path,\n",
        "    \"http://127.0.0.1:3030\"\n",
        ")\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now test the both the Torch model and ZKML model preformance by deploying it loaclly.\n",
        "\n",
        "Execute the 'app.py' file to run a Flask application server\n",
        "\n",
        "then Exeute the 'ZKP_test_api.py' to start the evaluation process of the predictioon, proof generation and verification process "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
